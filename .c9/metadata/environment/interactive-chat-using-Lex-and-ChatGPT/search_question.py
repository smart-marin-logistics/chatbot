{"filter":false,"title":"search_question.py","tooltip":"/interactive-chat-using-Lex-and-ChatGPT/search_question.py","undoManager":{"mark":19,"position":19,"stack":[[{"start":{"row":0,"column":0},"end":{"row":12,"column":0},"action":"insert","lines":["import openai","from PyPDF2 import PdfReader","from langchain.text_splitter import CharacterTextSplitter","from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS","import os","from langchain.vectorstores import Chroma","from langchain.embeddings import OpenAIEmbeddings","from langchain.text_splitter import RecursiveCharacterTextSplitter","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","from langchain.document_loaders import TextLoader","from langchain.document_loaders import DirectoryLoader",""],"id":21}],[{"start":{"row":12,"column":0},"end":{"row":13,"column":0},"action":"insert","lines":["",""],"id":22}],[{"start":{"row":13,"column":0},"end":{"row":13,"column":84},"action":"insert","lines":["os.environ[\"OPENAI_API_KEY\"] = \"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\""],"id":23}],[{"start":{"row":13,"column":84},"end":{"row":14,"column":0},"action":"insert","lines":["",""],"id":24},{"start":{"row":14,"column":0},"end":{"row":15,"column":0},"action":"insert","lines":["",""]}],[{"start":{"row":15,"column":0},"end":{"row":21,"column":33},"action":"insert","lines":["retriever = vectordb.as_retriever()","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True)"],"id":25}],[{"start":{"row":21,"column":33},"end":{"row":22,"column":0},"action":"insert","lines":["",""],"id":26},{"start":{"row":22,"column":0},"end":{"row":22,"column":4},"action":"insert","lines":["    "]},{"start":{"row":22,"column":4},"end":{"row":23,"column":0},"action":"insert","lines":["",""]},{"start":{"row":23,"column":0},"end":{"row":23,"column":4},"action":"insert","lines":["    "]}],[{"start":{"row":23,"column":0},"end":{"row":23,"column":4},"action":"remove","lines":["    "],"id":27},{"start":{"row":22,"column":4},"end":{"row":23,"column":0},"action":"remove","lines":["",""]},{"start":{"row":22,"column":0},"end":{"row":22,"column":4},"action":"remove","lines":["    "]}],[{"start":{"row":22,"column":0},"end":{"row":23,"column":0},"action":"insert","lines":["",""],"id":28}],[{"start":{"row":23,"column":0},"end":{"row":54,"column":34},"action":"insert","lines":["import openai  # OpenAI 라이브러리를 사용합니다.","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","# 질문 작성하기","query = \"항만이란?\"","# 메시지 설정하기","messages = [","        {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","        {\"role\": \"user\", \"content\": query}","]","","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","openai.api_key = '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'","","# 여러 질문에 대한 응답 처리","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","        model=model,","        messages=messages","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else : ","        print(llm_response['result'])  # 응답 결과 출력","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])  # 응답 소스 문서 출력","llm_response = qa_chain(query)","process_llm_response(llm_response)"],"id":29}],[{"start":{"row":0,"column":0},"end":{"row":54,"column":34},"action":"remove","lines":["import openai","from PyPDF2 import PdfReader","from langchain.text_splitter import CharacterTextSplitter","from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS","import os","from langchain.vectorstores import Chroma","from langchain.embeddings import OpenAIEmbeddings","from langchain.text_splitter import RecursiveCharacterTextSplitter","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","from langchain.document_loaders import TextLoader","from langchain.document_loaders import DirectoryLoader","","os.environ[\"OPENAI_API_KEY\"] = \"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\"","","retriever = vectordb.as_retriever()","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True)","","import openai  # OpenAI 라이브러리를 사용합니다.","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","# 질문 작성하기","query = \"항만이란?\"","# 메시지 설정하기","messages = [","        {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","        {\"role\": \"user\", \"content\": query}","]","","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","openai.api_key = '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'","","# 여러 질문에 대한 응답 처리","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","        model=model,","        messages=messages","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else : ","        print(llm_response['result'])  # 응답 결과 출력","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])  # 응답 소스 문서 출력","llm_response = qa_chain(query)","process_llm_response(llm_response)"],"id":30},{"start":{"row":0,"column":0},"end":{"row":46,"column":0},"action":"insert","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.embeddings import OpenAIEmbeddings","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스 로드","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""]}],[{"start":{"row":14,"column":23},"end":{"row":14,"column":24},"action":"insert","lines":["ㅁ"],"id":31}],[{"start":{"row":14,"column":23},"end":{"row":14,"column":24},"action":"remove","lines":["ㅁ"],"id":32}],[{"start":{"row":16,"column":32},"end":{"row":16,"column":33},"action":"insert","lines":["ㅁ"],"id":33},{"start":{"row":16,"column":32},"end":{"row":16,"column":33},"action":"remove","lines":["ㅁ"]}],[{"start":{"row":0,"column":0},"end":{"row":46,"column":0},"action":"remove","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.embeddings import OpenAIEmbeddings","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스 로드","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""],"id":34},{"start":{"row":0,"column":0},"end":{"row":48,"column":0},"action":"insert","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# search_info.py 파일에서 필요한 객체와 함수를 가져옵니다.","from search_info import vectordb","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스 로드 (이제 필요 없습니다. 왜냐하면 search_info.py에서 이미 로드했기 때문입니다.)","# retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""]}],[{"start":{"row":0,"column":0},"end":{"row":48,"column":0},"action":"remove","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# search_info.py 파일에서 필요한 객체와 함수를 가져옵니다.","from search_info import vectordb","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스 로드 (이제 필요 없습니다. 왜냐하면 search_info.py에서 이미 로드했기 때문입니다.)","# retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""],"id":35},{"start":{"row":0,"column":0},"end":{"row":49,"column":0},"action":"insert","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# search_info.py 파일에서 필요한 객체와 함수를 가져옵니다.","from search_info import vectordb","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스를 이용해 retriever 객체 생성","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""]}],[{"start":{"row":16,"column":17},"end":{"row":16,"column":18},"action":"insert","lines":["a"],"id":36}],[{"start":{"row":16,"column":17},"end":{"row":16,"column":18},"action":"remove","lines":["a"],"id":37}],[{"start":{"row":12,"column":0},"end":{"row":49,"column":0},"action":"remove","lines":["# 벡터 데이터베이스를 이용해 retriever 객체 생성","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""],"id":38},{"start":{"row":12,"column":0},"end":{"row":53,"column":0},"action":"insert","lines":["# 벡터 데이터베이스 로드","persist_directory = './pdf_db'","embedding = OpenAIEmbeddings() ","vectordb = Chroma(","    persist_directory=persist_directory,","    embedding_function=embedding",")","","# 벡터 데이터베이스를 이용해 retriever 객체 생성","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 미리 설정된 질문","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""]}],[{"start":{"row":8,"column":0},"end":{"row":9,"column":0},"action":"insert","lines":["from langchain.embeddings import OpenAIEmbeddings",""],"id":39}],[{"start":{"row":0,"column":0},"end":{"row":54,"column":0},"action":"remove","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# search_info.py 파일에서 필요한 객체와 함수를 가져옵니다.","from search_info import vectordb","from langchain.embeddings import OpenAIEmbeddings","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스 로드","persist_directory = './pdf_db'","embedding = OpenAIEmbeddings() ","vectordb = Chroma(","    persist_directory=persist_directory,","    embedding_function=embedding",")","","# 벡터 데이터베이스를 이용해 retriever 객체 생성","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 미리 설정된 질문","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""],"id":40},{"start":{"row":0,"column":0},"end":{"row":49,"column":0},"action":"insert","lines":["import os","import openai","from langchain.vectorstores import Chroma","from langchain.llms import OpenAI","from langchain.chains import RetrievalQA","","# search_info.py 파일에서 필요한 객체와 함수를 가져옵니다.","from search_info import vectordb","","# OpenAI API 키 설정","openai.api_key = \"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\"","","# 벡터 데이터베이스를 이용해 retriever 객체 생성","retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})","","qa_chain = RetrievalQA.from_chain_type(","    llm=OpenAI(),","    chain_type=\"stuff\",","    retriever=retriever,","    return_source_documents=True",")","","# 모델 - GPT 3.5 Turbo 선택","model = \"gpt-3.5-turbo\"","ambiguous_responses = [\"I don't know.\", \"모르겠어요.\", \"모르겠습니다.\", \"확인할 수 없습니다.\"]","","def process_llm_response(llm_response):","    if any(response in llm_response['result'] for response in ambiguous_responses):","        # ChatGPT API 호출하기","        response = openai.ChatCompletion.create(","            model=model,","            messages=[","                {\"role\": \"system\", \"content\": \"You are a well-informed system of port information.\"},","                {\"role\": \"user\", \"content\": query}","            ]","        )","        answer = response['choices'][0]['message']['content']","        print(answer)","    else: ","        print(llm_response['result'])","        ","    print('\\n\\nSources:')","    for source in llm_response[\"source_documents\"]:","        print(source.metadata['source'])","","# 질문 작성하기","query = \"항만이란?\"","llm_response = qa_chain(query)","process_llm_response(llm_response)",""]}]]},"ace":{"folds":[],"scrolltop":312.50244140625,"scrollleft":0,"selection":{"start":{"row":11,"column":0},"end":{"row":11,"column":0},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":{"row":2,"state":"start","mode":"ace/mode/python"}},"timestamp":1692345521505,"hash":"05c9c113c398370eb4ca13e1bf682c46be3f29ef"}